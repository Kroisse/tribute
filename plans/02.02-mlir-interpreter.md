# MLIR Interpreter Implementation Plan

**Status**: 📋 **PLANNED** - Not yet started  
**Prerequisites**: ✅ Modern Syntax (Plan 01), ✅ String Interpolation (Plan 01.01), 📋 HIR to MLIR (Plan 02.01)  
**Estimated Timeline**: 2-3 weeks  
**Complexity**: Medium-Low  
**Next Step**: 📋 Native Compilation (Plan 02)

## Overview

This plan implements an interpreter that executes MLIR operations directly, building on the Tribute dialect established in Plan 02.01. With the HIR→MLIR lowering already complete, this step focuses purely on MLIR execution, serving as validation for native compilation.

### Strategic Goals

1. **MLIR Foundation**: Establish Tribute dialect and basic infrastructure
2. **Optimization Testing**: Validate MLIR passes with real execution
3. **Native Preparation**: Create foundation for Plan 02 native compilation
4. **Performance Insight**: Measure benefits of MLIR optimizations
5. **Incremental Migration**: Gradual transition from HIR to MLIR

## Architecture Overview

### Execution Pipeline

```
Tribute Source → AST → Tribute MLIR Dialect → MLIR Passes → MLIR Interpreter
```

**vs Current:**
```
Tribute Source → AST → HIR → HIR Evaluator
```

### Benefits Over Direct HIR

1. **MLIR Pass Pipeline**: Apply optimizations before interpretation
2. **Structured IR**: Better debugging and analysis tools
3. **Native Preparation**: Same IR used for eventual compilation
4. **Optimization Validation**: Test pass effectiveness with real execution

## Implementation Phases

### Phase 1: Interpreter Foundation (1 week)

**Goal**: Set up MLIR interpretation infrastructure

**Given from Plan 02.01**:
- ✅ Complete Tribute dialect (TableGen + C++)
- ✅ HIR → MLIR lowering pipeline
- ✅ FFI bindings for operation creation
- ✅ All core operations defined

**New Work**:
```rust
// Interpreter core structure
pub struct TributeMLIRInterpreter {
    runtime: TributeRuntime,           // Reuse existing runtime
    execution_context: ExecutionContext,
    call_stack: Vec<ExecutionFrame>,
}
```

**Deliverables**:
- Interpreter execution framework
- MLIR operation → runtime value mapping
- Basic execution loop structure

### Phase 2: MLIR Interpreter Core (2-3 weeks)

**Goal**: Execute MLIR operations with runtime value system

```rust
pub struct TributeMLIRInterpreter {
    runtime: TributeRuntime,           // Reuse existing runtime
    execution_context: ExecutionContext,
    mlir_module: Module,
}

impl TributeMLIRInterpreter {
    pub fn execute(&mut self, module: Module) -> Result<Value, RuntimeError> {
        // Find main function or top-level expressions
        let entry_point = self.find_entry_point(&module)?;
        
        // Execute operations in order
        self.execute_region(&entry_point)
    }
    
    fn execute_operation(&mut self, op: &Operation) -> Result<Vec<Value>, RuntimeError> {
        match op.name().as_str() {
            "tribute.constant" => self.exec_constant(op),
            "tribute.add" => self.exec_binary_op(op, BinaryOp::Add),
            "tribute.call" => self.exec_call(op),
            "tribute.func" => self.exec_func_def(op),
            "tribute.return" => self.exec_return(op),
            _ => Err(RuntimeError::UnsupportedOperation(op.name().to_string()))
        }
    }
}
```

**Deliverables**:
- Core interpreter loop
- Operation execution handlers
- Value mapping (MLIR ↔ Runtime)
- Error handling and diagnostics

### Phase 3: Control Flow & Advanced Features (2-3 weeks)

**Goal**: Support complete language features

```rust
// Additional operations
tribute.if          // Conditional execution
tribute.while       // Loop constructs  
tribute.match       // Pattern matching
tribute.string_interpolation  // String features
tribute.list_create // Collection operations
```

**Deliverables**:
- Control flow execution
- Block/region navigation
- Pattern matching support
- String interpolation
- Collection operations

### Phase 4: Integration & Optimization (1-2 weeks)

**Goal**: Complete integration with existing toolchain

**Deliverables**:
- HIR → MLIR lowering pipeline
- MLIR pass integration
- Performance benchmarking
- Comprehensive testing

## Technical Implementation

### HIR to MLIR Lowering

```rust
// src/hir_to_mlir.rs
pub struct HirToMLIRLowerer<'c> {
    context: &'c Context,
    builder: TributeMLIRBuilder<'c>,
    symbol_table: HashMap<String, Value<'c, '_>>,
}

impl<'c> HirToMLIRLowerer<'c> {
    pub fn lower_program(&mut self, program: &HirProgram) -> Result<Module<'c>, LoweringError> {
        let module = Module::new(Location::unknown(self.context));
        
        for item in program.items() {
            match item {
                HirItem::Function(func) => {
                    self.lower_function(func)?;
                }
                HirItem::Expression(expr) => {
                    self.lower_top_level_expression(expr)?;
                }
            }
        }
        
        Ok(module)
    }
    
    fn lower_function(&mut self, func: &HirFunction) -> Result<Operation<'c>, LoweringError> {
        // Create tribute.func operation
        let func_op = self.builder.create_function(
            &func.name,
            func.params.iter().map(|p| (p.as_str(), self.builder.get_value_type())).collect(),
            Some(self.builder.get_value_type()),
            |builder, entry_block| {
                // Lower function body
                self.lower_expression(&func.body, builder, entry_block)
            }
        );
        
        Ok(func_op)
    }
}
```

### MLIR Interpreter Execution

```rust
// src/mlir_interpreter.rs
impl TributeMLIRInterpreter {
    fn exec_constant(&mut self, op: &Operation) -> Result<Vec<Value>, RuntimeError> {
        let value_attr = op.attribute("value").unwrap();
        let runtime_value = match value_attr {
            Attribute::Float(f) => self.runtime.create_number(f.value()),
            Attribute::String(s) => self.runtime.create_string(s.value()),
            Attribute::Integer(i) => self.runtime.create_number(i.value() as f64),
            _ => return Err(RuntimeError::InvalidConstant),
        };
        Ok(vec![runtime_value])
    }
    
    fn exec_binary_op(&mut self, op: &Operation, op_type: BinaryOp) -> Result<Vec<Value>, RuntimeError> {
        let lhs = self.get_operand_value(op, 0)?;
        let rhs = self.get_operand_value(op, 1)?;
        
        let result = match op_type {
            BinaryOp::Add => self.runtime.add(lhs, rhs)?,
            BinaryOp::Sub => self.runtime.subtract(lhs, rhs)?,
            BinaryOp::Mul => self.runtime.multiply(lhs, rhs)?,
            BinaryOp::Div => self.runtime.divide(lhs, rhs)?,
        };
        
        Ok(vec![result])
    }
    
    fn exec_call(&mut self, op: &Operation) -> Result<Vec<Value>, RuntimeError> {
        let func_name = self.get_function_name(op)?;
        let args = self.get_operand_values(op, 1..)?;
        
        // Look up function in MLIR module
        let func_op = self.find_function(&func_name)?;
        
        // Create new execution frame
        let frame = ExecutionFrame::new(func_op, args);
        self.call_stack.push(frame);
        
        // Execute function body
        let result = self.execute_region(func_op.body())?;
        
        self.call_stack.pop();
        Ok(vec![result])
    }
}
```

## Integration with Existing System

### Unified API

```rust
// src/lib.rs - Updated main API
pub fn eval_str(db: &dyn TributeDatabase, filename: &str, input: &str) -> Result<Value, EvalError> {
    // Parse to AST (existing)
    let (program, _) = parse_str(db, filename, input);
    
    // Lower to HIR (existing)  
    let hir_program = lower_ast_to_hir(db, program);
    
    // NEW: Choose execution backend
    match get_execution_backend() {
        ExecutionBackend::HIR => {
            // Existing HIR evaluation
            eval_hir_program(db, hir_program)
        }
        ExecutionBackend::MLIR => {
            // NEW: MLIR interpretation
            eval_mlir_program(db, hir_program)
        }
    }
}

fn eval_mlir_program(db: &dyn TributeDatabase, program: HirProgram) -> Result<Value, EvalError> {
    let context = Context::new();
    let mut lowerer = HirToMLIRLowerer::new(&context);
    
    // Lower HIR to MLIR
    let mlir_module = lowerer.lower_program(&program)?;
    
    // Apply optimization passes
    let mut pass_manager = PassManager::new(&context);
    pass_manager.add_pass(create_canonicalizer());
    pass_manager.add_pass(create_cse());
    pass_manager.run(&mlir_module)?;
    
    // Interpret MLIR
    let mut interpreter = TributeMLIRInterpreter::new();
    interpreter.execute(mlir_module)
}
```

## Testing Strategy

### Unit Tests
```rust
#[test]
fn test_mlir_arithmetic() {
    let input = "1 + 2 * 3";
    let result = eval_str_with_mlir(&input).unwrap();
    assert_eq!(result.as_number(), Some(7.0));
}

#[test] 
fn test_mlir_function_call() {
    let input = r#"
        fn add(a, b) { a + b }
        add(5, 3)
    "#;
    let result = eval_str_with_mlir(&input).unwrap();
    assert_eq!(result.as_number(), Some(8.0));
}
```

### Integration Tests
- Compare HIR vs MLIR results for identical programs
- Performance benchmarks
- Memory usage analysis

### MLIR-Specific Tests
- Verify pass pipeline effects
- Test MLIR IR generation correctness
- Validate optimization benefits

## Performance Expectations

### Comparison Matrix

| Metric | HIR Direct | MLIR Interp | Improvement |
|--------|------------|-------------|-------------|
| **Startup** | ~1ms | ~5-10ms | -5-9x (MLIR overhead) |
| **Simple Arithmetic** | ~100ns/op | ~200ns/op | -2x (interpretation overhead) |
| **Function Calls** | ~1μs | ~1.5μs | -1.5x |
| **Optimized Code** | baseline | +10-50% | +10-50% (pass benefits) |

### Expected Benefits
- **Constant folding**: Pre-compute known values
- **Dead code elimination**: Remove unused operations
- **Function inlining**: Eliminate small function overhead
- **Common subexpression elimination**: Reduce redundant calculations

## Risk Assessment

### Low Risk
- ✅ Reuse existing runtime system
- ✅ Leverage proven HIR evaluation logic
- ✅ MLIR infrastructure is mature

### Medium Risk  
- ⚠️ FFI complexity with custom dialect
- ⚠️ Learning curve for MLIR APIs
- ⚠️ Integration with melior limitations

### High Risk
- 🔴 Performance regression vs HIR
- 🔴 Complex debugging across FFI boundary

### Mitigation Strategies
- Maintain HIR evaluation as fallback
- Comprehensive benchmarking at each phase
- Extensive integration testing
- Clear performance regression criteria

## Success Criteria

### Functional
- [ ] All existing HIR tests pass with MLIR backend
- [ ] Feature parity: functions, arithmetic, strings, pattern matching
- [ ] Error handling equivalent to HIR system
- [ ] Debug information preservation

### Performance
- [ ] Startup overhead < 10ms for typical programs
- [ ] Execution speed within 2x of HIR for unoptimized code
- [ ] Measurable optimization benefits for complex programs
- [ ] Memory usage comparable to HIR

### Quality
- [ ] Comprehensive test coverage (>90%)
- [ ] Documentation for MLIR dialect
- [ ] Integration with existing toolchain
- [ ] Clear migration path to native compilation

## Next Steps

1. **Immediate**: Implement basic TableGen dialect definition
2. **Week 1-2**: Core operation set and FFI bindings  
3. **Week 3-4**: Basic interpreter loop and value system
4. **Week 5-6**: Control flow and advanced features
5. **Week 7-8**: Integration, optimization, and testing

This plan provides a solid foundation for Plan 02 native compilation while delivering immediate value through MLIR optimizations and better tooling support.