# MLIR Interpreter Implementation Plan

**Status**: üìã **PLANNED** - Not yet started  
**Prerequisites**: ‚úÖ Modern Syntax (Plan 01), ‚úÖ String Interpolation (Plan 01.01), üìã HIR to MLIR (Plan 02.01)  
**Estimated Timeline**: 2-3 weeks  
**Complexity**: Medium-Low  
**Next Step**: üìã Native Compilation (Plan 02)

## Overview

This plan implements an interpreter that executes MLIR operations directly, building on the Tribute dialect established in Plan 02.01. With the HIR‚ÜíMLIR lowering already complete, this step focuses purely on MLIR execution, serving as validation for native compilation.

### Strategic Goals

1. **MLIR Foundation**: Establish Tribute dialect and basic infrastructure
2. **Optimization Testing**: Validate MLIR passes with real execution
3. **Native Preparation**: Create foundation for Plan 02 native compilation
4. **Performance Insight**: Measure benefits of MLIR optimizations
5. **Incremental Migration**: Gradual transition from HIR to MLIR

## Architecture Overview

### Execution Pipeline

```
Tribute Source ‚Üí AST ‚Üí Tribute MLIR Dialect ‚Üí MLIR Passes ‚Üí MLIR Interpreter
```

**vs Current:**
```
Tribute Source ‚Üí AST ‚Üí HIR ‚Üí HIR Evaluator
```

### Benefits Over Direct HIR

1. **MLIR Pass Pipeline**: Apply optimizations before interpretation
2. **Structured IR**: Better debugging and analysis tools
3. **Native Preparation**: Same IR used for eventual compilation
4. **Optimization Validation**: Test pass effectiveness with real execution

## Implementation Phases

### Phase 1: Interpreter Foundation (1 week)

**Goal**: Set up MLIR interpretation infrastructure

**Given from Plan 02.01**:
- ‚úÖ Complete Tribute dialect (TableGen + C++)
- ‚úÖ HIR ‚Üí MLIR lowering pipeline
- ‚úÖ FFI bindings for operation creation
- ‚úÖ All core operations defined

**New Work**:
```rust
// Interpreter core structure
pub struct TributeMLIRInterpreter {
    runtime: TributeRuntime,           // Reuse existing runtime
    execution_context: ExecutionContext,
    call_stack: Vec<ExecutionFrame>,
}
```

**Deliverables**:
- Interpreter execution framework
- MLIR operation ‚Üí runtime value mapping
- Basic execution loop structure

### Phase 2: MLIR Interpreter Core (2-3 weeks)

**Goal**: Execute MLIR operations with runtime value system

```rust
pub struct TributeMLIRInterpreter {
    runtime: TributeRuntime,           // Reuse existing runtime
    execution_context: ExecutionContext,
    mlir_module: Module,
}

impl TributeMLIRInterpreter {
    pub fn execute(&mut self, module: Module) -> Result<Value, RuntimeError> {
        // Find main function or top-level expressions
        let entry_point = self.find_entry_point(&module)?;
        
        // Execute operations in order
        self.execute_region(&entry_point)
    }
    
    fn execute_operation(&mut self, op: &Operation) -> Result<Vec<Value>, RuntimeError> {
        match op.name().as_str() {
            "tribute.constant" => self.exec_constant(op),
            "tribute.add" => self.exec_binary_op(op, BinaryOp::Add),
            "tribute.call" => self.exec_call(op),
            "tribute.func" => self.exec_func_def(op),
            "tribute.return" => self.exec_return(op),
            _ => Err(RuntimeError::UnsupportedOperation(op.name().to_string()))
        }
    }
}
```

**Deliverables**:
- Core interpreter loop
- Operation execution handlers
- Value mapping (MLIR ‚Üî Runtime)
- Error handling and diagnostics

### Phase 3: Control Flow & Advanced Features (2-3 weeks)

**Goal**: Support complete language features

```rust
// Additional operations
tribute.if          // Conditional execution
tribute.while       // Loop constructs  
tribute.match       // Pattern matching
tribute.string_interpolation  // String features
tribute.list_create // Collection operations
```

**Deliverables**:
- Control flow execution
- Block/region navigation
- Pattern matching support
- String interpolation
- Collection operations

### Phase 4: Integration & Optimization (1-2 weeks)

**Goal**: Complete integration with existing toolchain

**Deliverables**:
- HIR ‚Üí MLIR lowering pipeline
- MLIR pass integration
- Performance benchmarking
- Comprehensive testing

## Technical Implementation

### HIR to MLIR Lowering

```rust
// src/hir_to_mlir.rs
pub struct HirToMLIRLowerer<'c> {
    context: &'c Context,
    builder: TributeMLIRBuilder<'c>,
    symbol_table: HashMap<String, Value<'c, '_>>,
}

impl<'c> HirToMLIRLowerer<'c> {
    pub fn lower_program(&mut self, program: &HirProgram) -> Result<Module<'c>, LoweringError> {
        let module = Module::new(Location::unknown(self.context));
        
        for item in program.items() {
            match item {
                HirItem::Function(func) => {
                    self.lower_function(func)?;
                }
                HirItem::Expression(expr) => {
                    self.lower_top_level_expression(expr)?;
                }
            }
        }
        
        Ok(module)
    }
    
    fn lower_function(&mut self, func: &HirFunction) -> Result<Operation<'c>, LoweringError> {
        // Create tribute.func operation
        let func_op = self.builder.create_function(
            &func.name,
            func.params.iter().map(|p| (p.as_str(), self.builder.get_value_type())).collect(),
            Some(self.builder.get_value_type()),
            |builder, entry_block| {
                // Lower function body
                self.lower_expression(&func.body, builder, entry_block)
            }
        );
        
        Ok(func_op)
    }
}
```

### MLIR Interpreter Execution

```rust
// src/mlir_interpreter.rs
impl TributeMLIRInterpreter {
    fn exec_constant(&mut self, op: &Operation) -> Result<Vec<Value>, RuntimeError> {
        let value_attr = op.attribute("value").unwrap();
        let runtime_value = match value_attr {
            Attribute::Float(f) => self.runtime.create_number(f.value()),
            Attribute::String(s) => self.runtime.create_string(s.value()),
            Attribute::Integer(i) => self.runtime.create_number(i.value() as f64),
            _ => return Err(RuntimeError::InvalidConstant),
        };
        Ok(vec![runtime_value])
    }
    
    fn exec_binary_op(&mut self, op: &Operation, op_type: BinaryOp) -> Result<Vec<Value>, RuntimeError> {
        let lhs = self.get_operand_value(op, 0)?;
        let rhs = self.get_operand_value(op, 1)?;
        
        let result = match op_type {
            BinaryOp::Add => self.runtime.add(lhs, rhs)?,
            BinaryOp::Sub => self.runtime.subtract(lhs, rhs)?,
            BinaryOp::Mul => self.runtime.multiply(lhs, rhs)?,
            BinaryOp::Div => self.runtime.divide(lhs, rhs)?,
        };
        
        Ok(vec![result])
    }
    
    fn exec_call(&mut self, op: &Operation) -> Result<Vec<Value>, RuntimeError> {
        let func_name = self.get_function_name(op)?;
        let args = self.get_operand_values(op, 1..)?;
        
        // Look up function in MLIR module
        let func_op = self.find_function(&func_name)?;
        
        // Create new execution frame
        let frame = ExecutionFrame::new(func_op, args);
        self.call_stack.push(frame);
        
        // Execute function body
        let result = self.execute_region(func_op.body())?;
        
        self.call_stack.pop();
        Ok(vec![result])
    }
}
```

## Integration with Existing System

### Unified API

```rust
// src/lib.rs - Updated main API
pub fn eval_str(db: &dyn TributeDatabase, filename: &str, input: &str) -> Result<Value, EvalError> {
    // Parse to AST (existing)
    let (program, _) = parse_str(db, filename, input);
    
    // Lower to HIR (existing)  
    let hir_program = lower_ast_to_hir(db, program);
    
    // NEW: Choose execution backend
    match get_execution_backend() {
        ExecutionBackend::HIR => {
            // Existing HIR evaluation
            eval_hir_program(db, hir_program)
        }
        ExecutionBackend::MLIR => {
            // NEW: MLIR interpretation
            eval_mlir_program(db, hir_program)
        }
    }
}

fn eval_mlir_program(db: &dyn TributeDatabase, program: HirProgram) -> Result<Value, EvalError> {
    let context = Context::new();
    let mut lowerer = HirToMLIRLowerer::new(&context);
    
    // Lower HIR to MLIR
    let mlir_module = lowerer.lower_program(&program)?;
    
    // Apply optimization passes
    let mut pass_manager = PassManager::new(&context);
    pass_manager.add_pass(create_canonicalizer());
    pass_manager.add_pass(create_cse());
    pass_manager.run(&mlir_module)?;
    
    // Interpret MLIR
    let mut interpreter = TributeMLIRInterpreter::new();
    interpreter.execute(mlir_module)
}
```

## Testing Strategy

### Unit Tests
```rust
#[test]
fn test_mlir_arithmetic() {
    let input = "1 + 2 * 3";
    let result = eval_str_with_mlir(&input).unwrap();
    assert_eq!(result.as_number(), Some(7.0));
}

#[test] 
fn test_mlir_function_call() {
    let input = r#"
        fn add(a, b) { a + b }
        add(5, 3)
    "#;
    let result = eval_str_with_mlir(&input).unwrap();
    assert_eq!(result.as_number(), Some(8.0));
}
```

### Integration Tests
- Compare HIR vs MLIR results for identical programs
- Performance benchmarks
- Memory usage analysis

### MLIR-Specific Tests
- Verify pass pipeline effects
- Test MLIR IR generation correctness
- Validate optimization benefits

## Performance Expectations

### Comparison Matrix

| Metric | HIR Direct | MLIR Interp | Improvement |
|--------|------------|-------------|-------------|
| **Startup** | ~1ms | ~5-10ms | -5-9x (MLIR overhead) |
| **Simple Arithmetic** | ~100ns/op | ~200ns/op | -2x (interpretation overhead) |
| **Function Calls** | ~1Œºs | ~1.5Œºs | -1.5x |
| **Optimized Code** | baseline | +10-50% | +10-50% (pass benefits) |

### Expected Benefits
- **Constant folding**: Pre-compute known values
- **Dead code elimination**: Remove unused operations
- **Function inlining**: Eliminate small function overhead
- **Common subexpression elimination**: Reduce redundant calculations

## Risk Assessment

### Low Risk
- ‚úÖ Reuse existing runtime system
- ‚úÖ Leverage proven HIR evaluation logic
- ‚úÖ MLIR infrastructure is mature

### Medium Risk  
- ‚ö†Ô∏è FFI complexity with custom dialect
- ‚ö†Ô∏è Learning curve for MLIR APIs
- ‚ö†Ô∏è Integration with melior limitations

### High Risk
- üî¥ Performance regression vs HIR
- üî¥ Complex debugging across FFI boundary

### Mitigation Strategies
- Maintain HIR evaluation as fallback
- Comprehensive benchmarking at each phase
- Extensive integration testing
- Clear performance regression criteria

## Success Criteria

### Functional
- [ ] All existing HIR tests pass with MLIR backend
- [ ] Feature parity: functions, arithmetic, strings, pattern matching
- [ ] Error handling equivalent to HIR system
- [ ] Debug information preservation

### Performance
- [ ] Startup overhead < 10ms for typical programs
- [ ] Execution speed within 2x of HIR for unoptimized code
- [ ] Measurable optimization benefits for complex programs
- [ ] Memory usage comparable to HIR

### Quality
- [ ] Comprehensive test coverage (>90%)
- [ ] Documentation for MLIR dialect
- [ ] Integration with existing toolchain
- [ ] Clear migration path to native compilation

## Next Steps

1. **Immediate**: Implement basic TableGen dialect definition
2. **Week 1-2**: Core operation set and FFI bindings  
3. **Week 3-4**: Basic interpreter loop and value system
4. **Week 5-6**: Control flow and advanced features
5. **Week 7-8**: Integration, optimization, and testing

This plan provides a solid foundation for Plan 02 native compilation while delivering immediate value through MLIR optimizations and better tooling support.